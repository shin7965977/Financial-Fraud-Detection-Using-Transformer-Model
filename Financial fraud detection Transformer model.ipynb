{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b5b46e7",
   "metadata": {},
   "source": [
    "# Financial fraud detection Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011258ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AdamW\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, recall_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d73dca",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6daac607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shin7\\AppData\\Local\\Temp\\ipykernel_11408\\4271020941.py:18: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('fraudTest.csv')\n",
    "\n",
    "# Fill missing values\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Outlier detection and replacement\n",
    "df['amt'] = np.where(df['amt'] > df['amt'].quantile(0.95), df['amt'].quantile(0.95), df['amt'])\n",
    "df['amt'] = np.where(df['amt'] < df['amt'].quantile(0.05), df['amt'].quantile(0.05), df['amt'])\n",
    "\n",
    "# Drop non-essential columns\n",
    "columns_to_drop = ['Unnamed: 0', 'cc_num', 'first', 'last', 'street', 'trans_num', 'unix_time']\n",
    "df.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Convert dates and extract components\n",
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "df['age'] = df['trans_date_trans_time'].dt.year - df['dob'].dt.year\n",
    "df['hour'] = df['trans_date_trans_time'].dt.hour\n",
    "df['day_of_week'] = df['trans_date_trans_time'].dt.dayofweek\n",
    "df.drop(columns=['trans_date_trans_time', 'dob'], axis=1, inplace=True)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = ['amt', 'age', 'hour', 'day_of_week']\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Define and encode categorical columns\n",
    "categorical_columns = ['gender', 'category', 'state', 'merchant', 'city', 'zip', 'job']\n",
    "label_encoders = {col: LabelEncoder().fit(df[col]) for col in categorical_columns}\n",
    "for col, encoder in label_encoders.items():\n",
    "    df[col] = encoder.transform(df[col])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('is_fraud', axis=1)\n",
    "y = df['is_fraud']\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Applying SMOTE to balance the dataset\n",
    "smote = SMOTE(sampling_strategy=0.2, random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Convert data to tensors\n",
    "X_train_categorical = torch.tensor(X_train[categorical_columns].values, dtype=torch.long)\n",
    "X_train_numerical = torch.tensor(X_train[numerical_columns].values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_categorical = torch.tensor(X_test[categorical_columns].values, dtype=torch.long)\n",
    "X_test_numerical = torch.tensor(X_test[numerical_columns].values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset = TensorDataset(X_train_categorical, X_train_numerical, y_train)\n",
    "test_dataset = TensorDataset(X_test_categorical, X_test_numerical, y_test)\n",
    "\n",
    "# Embedding dimensions\n",
    "embedding_sizes = [(len(label_encoders[col].classes_), min(10, (len(label_encoders[col].classes_)+1)//2)) for col in categorical_columns]\n",
    "num_numerical_features = X_train_numerical.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c0a02",
   "metadata": {},
   "source": [
    "## Create TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c505087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_numerical, embedding_sizes, num_classes=1, nhead=4, num_layers=1, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(num_classes, size) for num_classes, size in embedding_sizes])\n",
    "        total_emb_size = sum(size for _, size in embedding_sizes)\n",
    "        d_model = total_emb_size + num_numerical\n",
    "        \n",
    "        if d_model % nhead != 0:\n",
    "            while d_model % nhead != 0:\n",
    "                nhead -= 1\n",
    "            print(f\"Adjusted 'nhead' to {nhead} to be divisible by 'd_model' {d_model}\")\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=512,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.linear = nn.Linear(d_model, num_classes)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x_cat, x_num):\n",
    "        embeddings = [embedding(x_cat[:, i]) for i, embedding in enumerate(self.embeddings)]\n",
    "        x_emb = torch.cat(embeddings, dim=1)\n",
    "        x_combined = torch.cat((x_emb, x_num), dim=1).unsqueeze(1)\n",
    "        x_encoded = self.transformer_encoder(x_combined)\n",
    "        x_out = self.linear(x_encoded.squeeze(1))\n",
    "        return self.activation(x_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9d1567",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(learning_rate, dropout, num_layers, batch_size):\n",
    "    model = TransformerModel(\n",
    "        num_numerical=num_numerical_features,\n",
    "        embedding_sizes=embedding_sizes,\n",
    "        nhead=4,\n",
    "        num_layers=int(num_layers),\n",
    "        dropout=dropout\n",
    "    )\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.BCELoss(weight=torch.tensor([15.0]))  # Increased weight for positive class\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=int(batch_size), shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=int(batch_size), shuffle=False)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model_state = None\n",
    "    patience = 3\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(8):  # Increased maximum epochs\n",
    "        model.train()\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\")\n",
    "        for X_cat_batch, X_num_batch, y_batch in train_pbar:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_cat_batch, X_num_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        model.eval()\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        test_pbar = tqdm(test_loader, desc=f\"Epoch {epoch+1} Evaluation\")\n",
    "        with torch.no_grad():\n",
    "            for X_cat, X_num, y in test_pbar:\n",
    "                outputs = model(X_cat, X_num)\n",
    "                predictions = (outputs > 0.5).float()\n",
    "                y_true.extend(y.tolist())\n",
    "                y_pred.extend(predictions.flatten().tolist())\n",
    "        \n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        weighted_score = 0.3 * f1 + 0.7 * recall  # Weighted average\n",
    "        print(f\"Epoch {epoch+1}, F1: {f1:.4f}, Recall: {recall:.4f}, Weighted Score: {weighted_score:.4f}\")\n",
    "        \n",
    "        if weighted_score == 0:\n",
    "            print(f\"Weighted Score is 0. Stopping early and moving to next parameter combination.\")\n",
    "            return 0  # Return 0 to indicate this parameter combination is not good\n",
    "        \n",
    "        if weighted_score > best_score:\n",
    "            best_score = weighted_score\n",
    "            best_model_state = model.state_dict()\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        \n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # Load the best model state\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e143a8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shin7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Bayesian Optimization...\n",
      "|   iter    |  target   | batch_... |  dropout  | learni... | num_la... |\n",
      "-------------------------------------------------------------------------\n",
      "Adjusted 'nhead' to 2 to be divisible by 'd_model' 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 4622/4622 [00:56<00:00, 81.23it/s, Loss=1.1164]\n",
      "Epoch 1 Evaluation: 100%|██████████| 967/967 [00:02<00:00, 334.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, F1: 0.2062, Recall: 0.7343, Weighted Score: 0.5758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 4622/4622 [00:59<00:00, 78.09it/s, Loss=2.1134]\n",
      "Epoch 2 Evaluation: 100%|██████████| 967/967 [00:02<00:00, 349.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, F1: 0.2709, Recall: 0.8135, Weighted Score: 0.6507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 4622/4622 [00:59<00:00, 78.09it/s, Loss=0.4923]\n",
      "Epoch 3 Evaluation: 100%|██████████| 967/967 [00:02<00:00, 333.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, F1: 0.3625, Recall: 0.7925, Weighted Score: 0.6635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 4622/4622 [00:57<00:00, 80.86it/s, Loss=0.0712]\n",
      "Epoch 4 Evaluation: 100%|██████████| 967/967 [00:02<00:00, 322.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, F1: 0.3937, Recall: 0.7809, Weighted Score: 0.6647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 4622/4622 [00:55<00:00, 82.82it/s, Loss=0.0217]\n",
      "Epoch 5 Evaluation: 100%|██████████| 967/967 [00:02<00:00, 349.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, F1: 0.5023, Recall: 0.7692, Weighted Score: 0.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 4622/4622 [00:55<00:00, 83.09it/s, Loss=2.7751]\n",
      "Epoch 6 Evaluation: 100%|██████████| 967/967 [00:02<00:00, 330.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, F1: 0.4708, Recall: 0.7879, Weighted Score: 0.6927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 4622/4622 [00:55<00:00, 82.65it/s, Loss=0.0387]\n",
      "Epoch 7 Evaluation: 100%|██████████| 967/967 [00:02<00:00, 326.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, F1: 0.5402, Recall: 0.7902, Weighted Score: 0.7152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 4622/4622 [00:55<00:00, 82.85it/s, Loss=0.0073]\n",
      "Epoch 8 Evaluation: 100%|██████████| 967/967 [00:02<00:00, 355.18it/s]\n",
      "c:\\Users\\shin7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, F1: 0.5516, Recall: 0.7786, Weighted Score: 0.7105\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.7152   \u001b[39m | \u001b[39m115.9    \u001b[39m | \u001b[39m0.4803   \u001b[39m | \u001b[39m0.0007347\u001b[39m | \u001b[39m2.197    \u001b[39m |\n",
      "Adjusted 'nhead' to 2 to be divisible by 'd_model' 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 8052/8052 [01:21<00:00, 99.25it/s, Loss=2.2967] \n",
      "Epoch 1 Evaluation: 100%|██████████| 1684/1684 [00:03<00:00, 461.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, F1: 0.1525, Recall: 0.6830, Weighted Score: 0.5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 8052/8052 [01:25<00:00, 94.19it/s, Loss=2.1168] \n",
      "Epoch 2 Evaluation: 100%|██████████| 1684/1684 [00:03<00:00, 476.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, F1: 0.2151, Recall: 0.7133, Weighted Score: 0.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 8052/8052 [01:25<00:00, 94.67it/s, Loss=2.9540] \n",
      "Epoch 3 Evaluation: 100%|██████████| 1684/1684 [00:03<00:00, 518.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, F1: 0.2041, Recall: 0.7902, Weighted Score: 0.6144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 8052/8052 [01:27<00:00, 92.46it/s, Loss=1.6200]\n",
      "Epoch 4 Evaluation: 100%|██████████| 1684/1684 [00:03<00:00, 467.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, F1: 0.2337, Recall: 0.7995, Weighted Score: 0.6298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 8052/8052 [01:27<00:00, 91.62it/s, Loss=1.7209] \n",
      "Epoch 5 Evaluation: 100%|██████████| 1684/1684 [00:03<00:00, 503.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, F1: 0.2579, Recall: 0.8135, Weighted Score: 0.6468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 8052/8052 [01:24<00:00, 95.14it/s, Loss=1.1272] \n",
      "Epoch 6 Evaluation: 100%|██████████| 1684/1684 [00:03<00:00, 515.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, F1: 0.2648, Recall: 0.8298, Weighted Score: 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 8052/8052 [01:21<00:00, 99.24it/s, Loss=1.1042] \n",
      "Epoch 7 Evaluation: 100%|██████████| 1684/1684 [00:03<00:00, 494.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, F1: 0.3186, Recall: 0.8042, Weighted Score: 0.6585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 8052/8052 [01:22<00:00, 97.72it/s, Loss=0.4080] \n",
      "Epoch 8 Evaluation: 100%|██████████| 1684/1684 [00:03<00:00, 551.49it/s]\n",
      "c:\\Users\\shin7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, F1: 0.3287, Recall: 0.7995, Weighted Score: 0.6583\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.6603   \u001b[39m | \u001b[39m66.95    \u001b[39m | \u001b[39m0.1624   \u001b[39m | \u001b[39m6.75e-05 \u001b[39m | \u001b[39m2.732    \u001b[39m |\n",
      "Adjusted 'nhead' to 2 to be divisible by 'd_model' 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 3202/3202 [00:43<00:00, 73.42it/s, Loss=4.9232]\n",
      "Epoch 1 Evaluation: 100%|██████████| 670/670 [00:02<00:00, 233.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, F1: 0.0876, Recall: 0.6620, Weighted Score: 0.4897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 3202/3202 [00:51<00:00, 62.72it/s, Loss=3.8592]\n",
      "Epoch 2 Evaluation: 100%|██████████| 670/670 [00:03<00:00, 214.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, F1: 0.1002, Recall: 0.6667, Weighted Score: 0.4967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 3202/3202 [00:56<00:00, 56.55it/s, Loss=4.9703]\n",
      "Epoch 3 Evaluation: 100%|██████████| 670/670 [00:03<00:00, 198.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, F1: 0.1188, Recall: 0.6643, Weighted Score: 0.5007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 3202/3202 [00:57<00:00, 56.06it/s, Loss=0.9382]\n",
      "Epoch 4 Evaluation: 100%|██████████| 670/670 [00:03<00:00, 207.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, F1: 0.1320, Recall: 0.6550, Weighted Score: 0.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 3202/3202 [00:56<00:00, 56.84it/s, Loss=2.4836]\n",
      "Epoch 5 Evaluation: 100%|██████████| 670/670 [00:03<00:00, 197.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, F1: 0.1409, Recall: 0.6667, Weighted Score: 0.5089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 3202/3202 [00:56<00:00, 57.12it/s, Loss=2.9732]\n",
      "Epoch 6 Evaluation: 100%|██████████| 670/670 [00:03<00:00, 189.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, F1: 0.1497, Recall: 0.6876, Weighted Score: 0.5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 3202/3202 [00:56<00:00, 56.84it/s, Loss=3.8873]\n",
      "Epoch 7 Evaluation: 100%|██████████| 670/670 [00:03<00:00, 196.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, F1: 0.1504, Recall: 0.6853, Weighted Score: 0.5248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 3202/3202 [00:55<00:00, 57.18it/s, Loss=5.2560]\n",
      "Epoch 8 Evaluation: 100%|██████████| 670/670 [00:03<00:00, 200.26it/s]\n",
      "c:\\Users\\shin7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, F1: 0.1598, Recall: 0.6946, Weighted Score: 0.5342\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.5342   \u001b[39m | \u001b[39m166.6    \u001b[39m | \u001b[39m0.3832   \u001b[39m | \u001b[39m3.038e-05\u001b[39m | \u001b[39m2.94     \u001b[39m |\n",
      "Adjusted 'nhead' to 2 to be divisible by 'd_model' 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 4582/4582 [00:47<00:00, 97.08it/s, Loss=1.3913] \n",
      "Epoch 1 Evaluation: 100%|██████████| 959/959 [00:02<00:00, 370.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, F1: 0.2398, Recall: 0.7786, Weighted Score: 0.6169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 4582/4582 [00:48<00:00, 95.42it/s, Loss=2.0474] \n",
      "Epoch 2 Evaluation: 100%|██████████| 959/959 [00:02<00:00, 332.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, F1: 0.3015, Recall: 0.8228, Weighted Score: 0.6664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 4582/4582 [00:47<00:00, 96.70it/s, Loss=1.1985] \n",
      "Epoch 3 Evaluation: 100%|██████████| 959/959 [00:02<00:00, 331.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, F1: 0.3399, Recall: 0.8065, Weighted Score: 0.6665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 4582/4582 [00:48<00:00, 94.93it/s, Loss=0.7209] \n",
      "Epoch 4 Evaluation: 100%|██████████| 959/959 [00:02<00:00, 348.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, F1: 0.4425, Recall: 0.7483, Weighted Score: 0.6565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 4582/4582 [00:48<00:00, 95.35it/s, Loss=0.2454] \n",
      "Epoch 5 Evaluation: 100%|██████████| 959/959 [00:02<00:00, 339.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, F1: 0.5116, Recall: 0.7179, Weighted Score: 0.6561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 4582/4582 [00:47<00:00, 96.32it/s, Loss=0.9272] \n",
      "Epoch 6 Evaluation: 100%|██████████| 959/959 [00:02<00:00, 347.62it/s]\n",
      "c:\\Users\\shin7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, F1: 0.5427, Recall: 0.7110, Weighted Score: 0.6605\n",
      "Early stopping at epoch 6\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.6665   \u001b[39m | \u001b[39m116.9    \u001b[39m | \u001b[39m0.3299   \u001b[39m | \u001b[39m0.0007231\u001b[39m | \u001b[39m1.432    \u001b[39m |\n",
      "Adjusted 'nhead' to 2 to be divisible by 'd_model' 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 4703/4703 [01:24<00:00, 55.91it/s, Loss=2.4949]\n",
      "Epoch 1 Evaluation: 100%|██████████| 984/984 [00:04<00:00, 228.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, F1: 0.1835, Recall: 0.7459, Weighted Score: 0.5772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 4703/4703 [01:25<00:00, 54.69it/s, Loss=1.5470]\n",
      "Epoch 2 Evaluation: 100%|██████████| 984/984 [00:04<00:00, 218.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, F1: 0.2305, Recall: 0.8182, Weighted Score: 0.6419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 4703/4703 [01:29<00:00, 52.35it/s, Loss=1.9409]\n",
      "Epoch 3 Evaluation: 100%|██████████| 984/984 [00:03<00:00, 271.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, F1: 0.2789, Recall: 0.8205, Weighted Score: 0.6580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 4703/4703 [01:26<00:00, 54.42it/s, Loss=0.7534]\n",
      "Epoch 4 Evaluation: 100%|██████████| 984/984 [00:04<00:00, 228.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, F1: 0.3814, Recall: 0.7832, Weighted Score: 0.6627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 4703/4703 [01:30<00:00, 51.96it/s, Loss=0.9419]\n",
      "Epoch 5 Evaluation: 100%|██████████| 984/984 [00:04<00:00, 228.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, F1: 0.3840, Recall: 0.8159, Weighted Score: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 4703/4703 [01:30<00:00, 51.84it/s, Loss=0.6083]\n",
      "Epoch 6 Evaluation: 100%|██████████| 984/984 [00:04<00:00, 234.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, F1: 0.5060, Recall: 0.7343, Weighted Score: 0.6658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 4703/4703 [01:31<00:00, 51.65it/s, Loss=1.9816]\n",
      "Epoch 7 Evaluation: 100%|██████████| 984/984 [00:04<00:00, 224.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, F1: 0.5115, Recall: 0.8065, Weighted Score: 0.7180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 4703/4703 [01:30<00:00, 51.86it/s, Loss=0.3578]\n",
      "Epoch 8 Evaluation: 100%|██████████| 984/984 [00:04<00:00, 221.28it/s]\n",
      "c:\\Users\\shin7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, F1: 0.5686, Recall: 0.7483, Weighted Score: 0.6944\n",
      "| \u001b[35m5        \u001b[39m | \u001b[35m0.718    \u001b[39m | \u001b[35m113.7    \u001b[39m | \u001b[35m0.5      \u001b[39m | \u001b[35m0.0007709\u001b[39m | \u001b[35m3.0      \u001b[39m |\n",
      "Adjusted 'nhead' to 2 to be divisible by 'd_model' 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 4876/4876 [00:50<00:00, 96.67it/s, Loss=1.5741] \n",
      "Epoch 1 Evaluation: 100%|██████████| 1020/1020 [00:02<00:00, 370.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, F1: 0.1801, Recall: 0.7016, Weighted Score: 0.5452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 4876/4876 [00:49<00:00, 97.77it/s, Loss=1.5504] \n",
      "Epoch 2 Evaluation: 100%|██████████| 1020/1020 [00:03<00:00, 329.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, F1: 0.2205, Recall: 0.7646, Weighted Score: 0.6013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 4876/4876 [00:49<00:00, 97.94it/s, Loss=1.4629] \n",
      "Epoch 3 Evaluation: 100%|██████████| 1020/1020 [00:02<00:00, 344.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, F1: 0.2471, Recall: 0.8112, Weighted Score: 0.6420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 4876/4876 [00:49<00:00, 97.55it/s, Loss=1.1993] \n",
      "Epoch 4 Evaluation: 100%|██████████| 1020/1020 [00:02<00:00, 366.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, F1: 0.3177, Recall: 0.7949, Weighted Score: 0.6517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 4876/4876 [00:49<00:00, 97.56it/s, Loss=2.2487] \n",
      "Epoch 5 Evaluation: 100%|██████████| 1020/1020 [00:02<00:00, 342.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, F1: 0.3597, Recall: 0.7949, Weighted Score: 0.6643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 4876/4876 [00:49<00:00, 98.75it/s, Loss=0.3944] \n",
      "Epoch 6 Evaluation: 100%|██████████| 1020/1020 [00:02<00:00, 355.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, F1: 0.4123, Recall: 0.7646, Weighted Score: 0.6589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 4876/4876 [00:49<00:00, 98.08it/s, Loss=0.7395] \n",
      "Epoch 7 Evaluation: 100%|██████████| 1020/1020 [00:02<00:00, 347.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, F1: 0.4250, Recall: 0.7692, Weighted Score: 0.6660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 4876/4876 [00:49<00:00, 98.11it/s, Loss=1.4588] \n",
      "Epoch 8 Evaluation: 100%|██████████| 1020/1020 [00:02<00:00, 357.03it/s]\n",
      "c:\\Users\\shin7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, F1: 0.5040, Recall: 0.7343, Weighted Score: 0.6652\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.666    \u001b[39m | \u001b[39m109.3    \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m0.0003242\u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "Adjusted 'nhead' to 2 to be divisible by 'd_model' 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 6727/6727 [01:01<00:00, 109.78it/s, Loss=1.2153]\n",
      "Epoch 1 Evaluation: 100%|██████████| 1407/1407 [00:02<00:00, 546.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, F1: 0.2675, Recall: 0.7949, Weighted Score: 0.6366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 6727/6727 [00:58<00:00, 115.91it/s, Loss=1.5564]\n",
      "Epoch 2 Evaluation: 100%|██████████| 1407/1407 [00:03<00:00, 435.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, F1: 0.4111, Recall: 0.7576, Weighted Score: 0.6536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 6727/6727 [01:01<00:00, 109.31it/s, Loss=0.2046]\n",
      "Epoch 3 Evaluation: 100%|██████████| 1407/1407 [00:02<00:00, 503.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, F1: 0.4724, Recall: 0.6993, Weighted Score: 0.6312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 6727/6727 [01:03<00:00, 106.30it/s, Loss=0.3808]\n",
      "Epoch 4 Evaluation: 100%|██████████| 1407/1407 [00:03<00:00, 406.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, F1: 0.5225, Recall: 0.7040, Weighted Score: 0.6495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 6727/6727 [01:06<00:00, 100.92it/s, Loss=0.4488]\n",
      "Epoch 5 Evaluation: 100%|██████████| 1407/1407 [00:03<00:00, 397.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, F1: 0.5543, Recall: 0.7436, Weighted Score: 0.6868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 6727/6727 [01:04<00:00, 103.63it/s, Loss=0.1680]\n",
      "Epoch 6 Evaluation: 100%|██████████| 1407/1407 [00:02<00:00, 471.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, F1: 0.6194, Recall: 0.6713, Weighted Score: 0.6557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 6727/6727 [01:03<00:00, 106.38it/s, Loss=0.1498]\n",
      "Epoch 7 Evaluation: 100%|██████████| 1407/1407 [00:03<00:00, 448.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, F1: 0.6132, Recall: 0.7133, Weighted Score: 0.6833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 6727/6727 [01:02<00:00, 107.01it/s, Loss=0.7288]\n",
      "Epoch 8 Evaluation: 100%|██████████| 1407/1407 [00:03<00:00, 422.89it/s]\n",
      "c:\\Users\\shin7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, F1: 0.6571, Recall: 0.6946, Weighted Score: 0.6834\n",
      "Early stopping at epoch 8\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.6868   \u001b[39m | \u001b[39m79.11    \u001b[39m | \u001b[39m0.263    \u001b[39m | \u001b[39m0.0009886\u001b[39m | \u001b[39m1.214    \u001b[39m |\n",
      "Adjusted 'nhead' to 2 to be divisible by 'd_model' 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 6403/6403 [01:00<00:00, 106.43it/s, Loss=4.2635]\n",
      "Epoch 1 Evaluation: 100%|██████████| 1340/1340 [00:02<00:00, 468.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, F1: 0.1262, Recall: 0.7016, Weighted Score: 0.5290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 6403/6403 [01:00<00:00, 105.75it/s, Loss=2.8038]\n",
      "Epoch 2 Evaluation: 100%|██████████| 1340/1340 [00:03<00:00, 419.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, F1: 0.1745, Recall: 0.7203, Weighted Score: 0.5566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 6403/6403 [00:57<00:00, 112.32it/s, Loss=4.2301]\n",
      "Epoch 3 Evaluation: 100%|██████████| 1340/1340 [00:03<00:00, 415.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, F1: 0.2022, Recall: 0.7366, Weighted Score: 0.5763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 6403/6403 [01:00<00:00, 106.35it/s, Loss=1.5589]\n",
      "Epoch 4 Evaluation: 100%|██████████| 1340/1340 [00:02<00:00, 466.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, F1: 0.2166, Recall: 0.7319, Weighted Score: 0.5773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 6403/6403 [01:00<00:00, 105.97it/s, Loss=0.9885]\n",
      "Epoch 5 Evaluation: 100%|██████████| 1340/1340 [00:03<00:00, 422.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, F1: 0.2315, Recall: 0.7413, Weighted Score: 0.5883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 6403/6403 [00:59<00:00, 107.13it/s, Loss=1.9916]\n",
      "Epoch 6 Evaluation: 100%|██████████| 1340/1340 [00:03<00:00, 412.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, F1: 0.2335, Recall: 0.7692, Weighted Score: 0.6085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 6403/6403 [01:00<00:00, 106.44it/s, Loss=2.0091]\n",
      "Epoch 7 Evaluation: 100%|██████████| 1340/1340 [00:03<00:00, 446.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, F1: 0.2335, Recall: 0.7879, Weighted Score: 0.6216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 6403/6403 [01:00<00:00, 106.56it/s, Loss=1.3198]\n",
      "Epoch 8 Evaluation: 100%|██████████| 1340/1340 [00:03<00:00, 415.78it/s]\n",
      "c:\\Users\\shin7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, F1: 0.2717, Recall: 0.7762, Weighted Score: 0.6249\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.6249   \u001b[39m | \u001b[39m83.93    \u001b[39m | \u001b[39m0.4312   \u001b[39m | \u001b[39m7.917e-05\u001b[39m | \u001b[39m1.727    \u001b[39m |\n",
      "Adjusted 'nhead' to 2 to be divisible by 'd_model' 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 4703/4703 [00:48<00:00, 96.90it/s, Loss=4.1780] \n",
      "Epoch 1 Evaluation: 100%|██████████| 984/984 [00:03<00:00, 322.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, F1: 0.0998, Recall: 0.5851, Weighted Score: 0.4395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 4703/4703 [00:48<00:00, 97.22it/s, Loss=3.4397] \n",
      "Epoch 2 Evaluation: 100%|██████████| 984/984 [00:02<00:00, 378.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, F1: 0.0881, Recall: 0.7016, Weighted Score: 0.5176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 4703/4703 [00:48<00:00, 96.07it/s, Loss=4.1063] \n",
      "Epoch 3 Evaluation: 100%|██████████| 984/984 [00:03<00:00, 318.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, F1: 0.0905, Recall: 0.6946, Weighted Score: 0.5134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 4703/4703 [00:48<00:00, 96.53it/s, Loss=3.4642] \n",
      "Epoch 4 Evaluation: 100%|██████████| 984/984 [00:02<00:00, 345.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, F1: 0.0936, Recall: 0.7133, Weighted Score: 0.5274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 4703/4703 [00:48<00:00, 96.60it/s, Loss=2.8267] \n",
      "Epoch 5 Evaluation: 100%|██████████| 984/984 [00:02<00:00, 363.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, F1: 0.0978, Recall: 0.7016, Weighted Score: 0.5205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 4703/4703 [00:49<00:00, 95.27it/s, Loss=4.0880] \n",
      "Epoch 6 Evaluation: 100%|██████████| 984/984 [00:03<00:00, 323.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, F1: 0.1012, Recall: 0.6876, Weighted Score: 0.5117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 4703/4703 [00:48<00:00, 96.03it/s, Loss=3.8331] \n",
      "Epoch 7 Evaluation: 100%|██████████| 984/984 [00:02<00:00, 337.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, F1: 0.1022, Recall: 0.6853, Weighted Score: 0.5104\n",
      "Early stopping at epoch 7\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.5274   \u001b[39m | \u001b[39m113.8    \u001b[39m | \u001b[39m0.5      \u001b[39m | \u001b[39m1e-05    \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "=========================================================================\n",
      "Best parameters: {'batch_size': 113.68655735125606, 'dropout': 0.5, 'learning_rate': 0.0007709479958358504, 'num_layers': 3.0}\n",
      "Best score (average of F1 and Recall): 0.7180055716641082\n"
     ]
    }
   ],
   "source": [
    "# Bayesian Optimization\n",
    "pbounds = {\n",
    "    'learning_rate': (1e-5, 1e-3),\n",
    "    'dropout': (0.1, 0.5),\n",
    "    'num_layers': (1, 3),\n",
    "    'batch_size': (32, 256)\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=train_evaluate,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"Starting Bayesian Optimization...\")\n",
    "optimizer.maximize(\n",
    "    init_points=3,\n",
    "    n_iter=6,\n",
    ")\n",
    "\n",
    "print(\"Best parameters:\", optimizer.max['params'])\n",
    "print(\"Best score (average of F1 and Recall):\", optimizer.max['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5fa76",
   "metadata": {},
   "source": [
    "## Final Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad9af492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shin7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted 'nhead' to 2 to be divisible by 'd_model' 62\n",
      "Training final model with best parameters:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 4703/4703 [01:29<00:00, 52.84it/s, Loss=3.4589]\n",
      "Epoch 2 Training: 100%|██████████| 4703/4703 [01:31<00:00, 51.42it/s, Loss=1.4430]\n",
      "Epoch 3 Training: 100%|██████████| 4703/4703 [01:31<00:00, 51.33it/s, Loss=1.8285]\n",
      "Epoch 4 Training: 100%|██████████| 4703/4703 [01:14<00:00, 63.26it/s, Loss=0.7362]\n",
      "Epoch 5 Training: 100%|██████████| 4703/4703 [01:15<00:00, 62.24it/s, Loss=0.9194]\n",
      "Epoch 6 Training: 100%|██████████| 4703/4703 [01:16<00:00, 61.87it/s, Loss=0.3299]\n",
      "Epoch 7 Training: 100%|██████████| 4703/4703 [01:16<00:00, 61.75it/s, Loss=0.4941]\n",
      "Epoch 8 Training: 100%|██████████| 4703/4703 [01:16<00:00, 61.77it/s, Loss=0.5017]\n",
      "Epoch 9 Training: 100%|██████████| 4703/4703 [01:20<00:00, 58.27it/s, Loss=0.5119]\n",
      "Epoch 10 Training: 100%|██████████| 4703/4703 [01:20<00:00, 58.07it/s, Loss=0.2941]\n"
     ]
    }
   ],
   "source": [
    "# Train the final model with the best parameters\n",
    "best_params = optimizer.max['params']\n",
    "best_params['num_layers'] = int(best_params['num_layers'])\n",
    "best_params['batch_size'] = int(best_params['batch_size'])\n",
    "\n",
    "final_model = TransformerModel(\n",
    "    num_numerical=num_numerical_features,\n",
    "    embedding_sizes=embedding_sizes,\n",
    "    nhead=4,\n",
    "    num_layers=best_params['num_layers'],\n",
    "    dropout=best_params['dropout']\n",
    ")\n",
    "\n",
    "optimizer = AdamW(final_model.parameters(), lr=best_params['learning_rate'])\n",
    "criterion = nn.BCELoss(weight=torch.tensor([15.0]))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'], shuffle=False)\n",
    "\n",
    "print(\"Training final model with best parameters:\")\n",
    "for epoch in range(10):  # You can adjust the number of epochs\n",
    "    final_model.train()\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\")\n",
    "    for X_cat_batch, X_num_batch, y_batch in train_pbar:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(X_cat_batch, X_num_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1e977",
   "metadata": {},
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0c1fca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Evaluation:   0%|          | 0/984 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Evaluation: 100%|██████████| 984/984 [00:04<00:00, 245.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Results:\n",
      "F1 Score: 0.5554\n",
      "Recall: 0.7599\n",
      "Average Score: 0.6576\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    110715\n",
      "         1.0       0.44      0.76      0.56       429\n",
      "\n",
      "    accuracy                           1.00    111144\n",
      "   macro avg       0.72      0.88      0.78    111144\n",
      "weighted avg       1.00      1.00      1.00    111144\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[110296    419]\n",
      " [   103    326]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final model\n",
    "final_model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "test_pbar = tqdm(test_loader, desc=\"Final Evaluation\")\n",
    "with torch.no_grad():\n",
    "    for X_cat, X_num, y in test_pbar:\n",
    "        outputs = final_model(X_cat, X_num)\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        y_true.extend(y.tolist())\n",
    "        y_pred.extend(predictions.flatten().tolist())\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(f\"\\nFinal Model Results:\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Average Score: {(f1 + recall) / 2:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
